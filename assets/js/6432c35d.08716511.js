"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[462],{4137:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>g});var a=n(7294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var d=a.createContext({}),p=function(e){var t=a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},m=function(e){var t=p(e.components);return a.createElement(d.Provider,{value:t},e.children)},s="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,o=e.originalType,d=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),s=p(n),c=l,g=s["".concat(d,".").concat(c)]||s[c]||u[c]||o;return n?a.createElement(g,r(r({ref:t},m),{},{components:n})):a.createElement(g,r({ref:t},m))}));function g(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var o=n.length,r=new Array(o);r[0]=c;var i={};for(var d in t)hasOwnProperty.call(t,d)&&(i[d]=t[d]);i.originalType=e,i[s]="string"==typeof e?e:l,r[1]=i;for(var p=2;p<o;p++)r[p]=n[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},8466:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var a=n(7462),l=(n(7294),n(4137));const o={},r="Managing models",i={unversionedId:"Configuration/model-deployments",id:"Configuration/model-deployments",title:"Managing models",description:"The Management API",source:"@site/docs/30-Configuration/10-model-deployments.md",sourceDirName:"30-Configuration",slug:"/Configuration/model-deployments",permalink:"/azure-openai-service-proxy/Configuration/model-deployments",draft:!1,editUrl:"https://github.com/gloveboxes/azure-openai-service-proxy/tree/master/docs/docs/30-Configuration/10-model-deployments.md",tags:[],version:"current",sidebarPosition:10,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Proxy Management",permalink:"/azure-openai-service-proxy/category/proxy-management"},next:{title:"Managing Rate limits",permalink:"/azure-openai-service-proxy/Configuration/openai-rate-limits"}},d={},p=[{value:"The Management API",id:"the-management-api",level:2},{value:"Adding or updating as Azure OpenAI Model Deployment",id:"adding-or-updating-as-azure-openai-model-deployment",level:2},{value:"Model deployment classes",id:"model-deployment-classes",level:3},{value:"Load balancing",id:"load-balancing",level:3},{value:"Adding an Azure OpenAI model deployment",id:"adding-an-azure-openai-model-deployment",level:2},{value:"Listing Azure OpenAI Model Deployments",id:"listing-azure-openai-model-deployments",level:2},{value:"List all Azure OpenAI model deployments",id:"list-all-azure-openai-model-deployments",level:3},{value:"List active Azure OpenAI model deployments",id:"list-active-azure-openai-model-deployments",level:3}],m={toc:p},s="wrapper";function u(e){let{components:t,...n}=e;return(0,l.kt)(s,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"managing-models"},"Managing models"),(0,l.kt)("h2",{id:"the-management-api"},"The Management API"),(0,l.kt)("p",null,"There is a Management API for adding, updating, and list model deployments. The API is secured with a Management ID token. The Management ID token is stored in the Azure Storage Account ",(0,l.kt)("inlineCode",{parentName:"p"},"management")," table. The ",(0,l.kt)("inlineCode",{parentName:"p"},"management")," table is created when the proxy service is deployed and started."),(0,l.kt)("p",null,"For now, the only way to manage model depolyments is via the Management API. In the future, there may be a web UI for managing model deployments."),(0,l.kt)("h2",{id:"adding-or-updating-as-azure-openai-model-deployment"},"Adding or updating as Azure OpenAI Model Deployment"),(0,l.kt)("p",null,"There a Management API for adding Azure OpenAI model deployments to the system. The API is secured with a Management ID token. The Management ID token is stored in the Azure Storage Account ",(0,l.kt)("inlineCode",{parentName:"p"},"management")," table. The ",(0,l.kt)("inlineCode",{parentName:"p"},"management")," table is created when the proxy service is deployed and started."),(0,l.kt)("h3",{id:"model-deployment-classes"},"Model deployment classes"),(0,l.kt)("p",null,"The following is a list of the valid deployment classes supported by the Azure OpenAI proxy service."),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Model deployment class"),(0,l.kt)("th",{parentName:"tr",align:null},"Models"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"openai-chat")),(0,l.kt)("td",{parentName:"tr",align:null},"gpt-35-turbo, gpt-35-turbo-16k, or newer"),(0,l.kt)("td",{parentName:"tr",align:null},"This is the model deployment class for the Azure OpenAI Chat Completions API.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"openai-completions")),(0,l.kt)("td",{parentName:"tr",align:null},"davinci-002 or newer"),(0,l.kt)("td",{parentName:"tr",align:null},"This is the model deployment class for the Azure OpenAI Completions API.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"openai-embeddings")),(0,l.kt)("td",{parentName:"tr",align:null},"text-embedding-ada-002 or newer"),(0,l.kt)("td",{parentName:"tr",align:null},"This is the model deployment class for the Azure OpenAI Embeddings API.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("inlineCode",{parentName:"td"},"openai-images-generations")),(0,l.kt)("td",{parentName:"tr",align:null},"No model is deploy, just an Azure OpenAI resource in a location that supports the Images Generations API"),(0,l.kt)("td",{parentName:"tr",align:null},"This is the model deployment class for the Azure OpenAI Images Generations API.")))),(0,l.kt)("h3",{id:"load-balancing"},"Load balancing"),(0,l.kt)("p",null,"You can deploy multiple models of the same model deployment class. For example, you can deploy multiple ",(0,l.kt)("inlineCode",{parentName:"p"},"gpt-35-turbo")," models, you'd give them different ",(0,l.kt)("inlineCode",{parentName:"p"},"friendly_name")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"deployment_name")," values. The proxy will round robin across the models of the same model deployment class to balance the load."),(0,l.kt)("h2",{id:"adding-an-azure-openai-model-deployment"},"Adding an Azure OpenAI model deployment"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},'curl -X PATCH -H "Content-Type: application/json" -H "Authorization: Bearer YOUR_MANAGEMENT_ID_TOKEN" -d \'{\n    "deployment_class": "A_VALID_MODEL_DEPLOYMENT_CLASS",\n    "friendly_name" : "YOUR_AZURE_OPENAI_DEPLOYMENT_FRIENDLY_NAME",\n    "deployment_name": "YOUR_AZURE_OPENAI_DEPLOYMENT_NAME",\n    "endpoint_key": "YOUR_AZURE_OPENAI_ENDPOINT_KEY",\n    "resource_name": "YOUR_AZURE_OPENAI_RESOURCE_NAME",\n    "active": true\n}\' https://YOUR_OPENAI_PROXY_ENDPOINT/v1/api/management/modeldeployment/upsert\n')),(0,l.kt)("h2",{id:"listing-azure-openai-model-deployments"},"Listing Azure OpenAI Model Deployments"),(0,l.kt)("p",null,"You can list all Azure OpenAI model deployments or all active Azure OpenAI model deployments. The API is secured with a Management ID token. The Management ID token is stored in the Azure Storage Account ",(0,l.kt)("inlineCode",{parentName:"p"},"management")," table. The ",(0,l.kt)("inlineCode",{parentName:"p"},"management")," table is created when the proxy service is deployed and started."),(0,l.kt)("h3",{id:"list-all-azure-openai-model-deployments"},"List all Azure OpenAI model deployments"),(0,l.kt)("p",null,"The following is an example of a ",(0,l.kt)("inlineCode",{parentName:"p"},"cURL")," command to list all Azure OpenAI model deployments in the system."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},'https://YOUR_OPENAI_PROXY_ENDPOINT/v1/api/management/modeldeployment/list/all\ncurl -X GET -H "Authorization: Bearer YOUR_MANAGEMENT_ID_TOKEN" https://YOUR_OPENAI_PROXY_ENDPOINT/v1/api/management/listevents/all | jq\n')),(0,l.kt)("h3",{id:"list-active-azure-openai-model-deployments"},"List active Azure OpenAI model deployments"),(0,l.kt)("p",null,"An active Azure OpenAI model deployment is an Azure OpenAI model deployment where the ",(0,l.kt)("inlineCode",{parentName:"p"},"active")," property is set to ",(0,l.kt)("inlineCode",{parentName:"p"},"true"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},'curl -X GET -H "Authorization: Bearer YOUR_MANAGEMENT_ID_TOKEN" https://YOUR_OPENAI_PROXY_ENDPOINT/v1/api/management/listevents/active | jq\n')))}u.isMDXComponent=!0}}]);