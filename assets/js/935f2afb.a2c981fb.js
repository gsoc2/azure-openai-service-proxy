"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Azure OpenAI Proxy Service","href":"/azure-openai-service-proxy/","docId":"Introduction"},{"type":"category","label":"Service installation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"OpenAI proxy service","href":"/azure-openai-service-proxy/service-installation/OpenAI-Proxy","docId":"service-installation/OpenAI-Proxy"},{"type":"link","label":"Scaling the Proxy Service","href":"/azure-openai-service-proxy/service-installation/scaling-proxy-service","docId":"service-installation/scaling-proxy-service"},{"type":"category","label":"Testing","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Proxy service","href":"/azure-openai-service-proxy/service-installation/testing/testing","docId":"service-installation/testing/testing"},{"type":"link","label":"Load testing","href":"/azure-openai-service-proxy/service-installation/testing/load-testing","docId":"service-installation/testing/load-testing"}],"href":"/azure-openai-service-proxy/category/testing"}],"href":"/azure-openai-service-proxy/category/service-installation"},{"type":"link","label":"Playground installation","href":"/azure-openai-service-proxy/playground-installation","docId":"playground-installation"},{"type":"category","label":"Authorization","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Event authorization","href":"/azure-openai-service-proxy/Authorization/authorization","docId":"Authorization/authorization"},{"type":"link","label":"Azure OpenAI rate limits","href":"/azure-openai-service-proxy/Authorization/openai-rate-limits","docId":"Authorization/openai-rate-limits"},{"type":"link","label":"The Management API","href":"/azure-openai-service-proxy/Authorization/adding-event","docId":"Authorization/adding-event"}],"href":"/azure-openai-service-proxy/category/authorization"},{"type":"link","label":"OpenAI model deployments","href":"/azure-openai-service-proxy/openai-deployments","docId":"openai-deployments"},{"type":"link","label":"Using the Playground","href":"/azure-openai-service-proxy/playground","docId":"playground"},{"type":"category","label":"Developer endpoints","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Endpoint access","href":"/azure-openai-service-proxy/raw-api-access/introduction","docId":"raw-api-access/introduction"},{"type":"link","label":"Chat completions API","href":"/azure-openai-service-proxy/raw-api-access/chat-completion","docId":"raw-api-access/chat-completion"},{"type":"link","label":"Completions API","href":"/azure-openai-service-proxy/raw-api-access/completions","docId":"raw-api-access/completions"},{"type":"link","label":"Embeddings API","href":"/azure-openai-service-proxy/raw-api-access/embedding","docId":"raw-api-access/embedding"}],"href":"/azure-openai-service-proxy/category/developer-endpoints"}]},"docs":{"Authorization/adding-event":{"id":"Authorization/adding-event","title":"The Management API","description":"There is a Management API for adding events and listing events. The API is secured with a Management ID token. The Management ID token is stored in the Azure Storage Account management table. The management table is created when the proxy service is deployed and started.","sidebar":"tutorialSidebar"},"Authorization/authorization":{"id":"Authorization/authorization","title":"Event authorization","description":"Access to the proxy service endpoint is controlled by an event code.","sidebar":"tutorialSidebar"},"Authorization/openai-rate-limits":{"id":"Authorization/openai-rate-limits","title":"Azure OpenAI rate limits","description":"Azure OpenAI model deployments have two limits, the first being tokens per minute, and the second being requests per minute. You are most likely to hit the Tokens per minute limit especially as you scale up the number of users using the system.","sidebar":"tutorialSidebar"},"Introduction":{"id":"Introduction","title":"Azure OpenAI Proxy Service","description":"<Social","sidebar":"tutorialSidebar"},"openai-deployments":{"id":"openai-deployments","title":"OpenAI model deployments","description":"From the Azure Portal, select the Azure OpenAI resource, then select the Deployments tab, and finally select Create deployment. Enter a friendly name for the deployment, and select the model and the capacity. The capacity is the number of requests per minute. The capacity can be changed at any time. The deployment will take a few minutes to provision.","sidebar":"tutorialSidebar"},"playground":{"id":"playground","title":"Using the Playground","description":"The Playground is a web-based application that allows users to experiment with OpenAI Chat Completions.","sidebar":"tutorialSidebar"},"playground-installation":{"id":"playground-installation","title":"Playground installation","description":"to be completed","sidebar":"tutorialSidebar"},"raw-api-access/chat-completion":{"id":"raw-api-access/chat-completion","title":"Chat completions API","description":"The OpenAI proxy service chat completion endpoint is a REST API that generates a response to a messages. Requests are forwarded to the Azure OpenAI service and the response is returned to the caller.","sidebar":"tutorialSidebar"},"raw-api-access/completions":{"id":"raw-api-access/completions","title":"Completions API","description":"The OpenAI proxy service completion endpoint is a REST API that generates a response to a prompts. Requests are forwarded to the Azure OpenAI service and the response is returned to the caller.","sidebar":"tutorialSidebar"},"raw-api-access/embedding":{"id":"raw-api-access/embedding","title":"Embeddings API","description":"The OpenAI proxy service also supports the OpenAI Embeddings API. The Embeddings API is a REST API that generates embeddings for a given text. Requests are forwarded to the Azure OpenAI service and the response is returned to the caller.","sidebar":"tutorialSidebar"},"raw-api-access/introduction":{"id":"raw-api-access/introduction","title":"Endpoint access","description":"The Azure OpenAI proxy service provides access to the Azure OpenAI APIs for developers to build applications, again using a time bound event code. Initially, there are three REST endpoints available via the proxy service, chat completions, completions, and embeddings.","sidebar":"tutorialSidebar"},"service-installation/OpenAI-Proxy":{"id":"service-installation/OpenAI-Proxy","title":"OpenAI proxy service","description":"The solution consists of two parts; the proxy service and a web client with a similar look and feel to the official Azure OpenAI Playground. The proxy service is a Python FastAPI app that proxies requests to the OpenAI API.","sidebar":"tutorialSidebar"},"service-installation/scaling-proxy-service":{"id":"service-installation/scaling-proxy-service","title":"Scaling the Proxy Service","description":"The proxy service is stateless and scales vertically and horizontally. By default, the proxy service is configured to scale up to 10 replicas. The proxy service is configured to scale up to 10 replicas. The number of replicas can be changed from the Azure Portal or from the az cli. For example, to scale to 30 replicas using the az cli, change the:","sidebar":"tutorialSidebar"},"service-installation/testing/load-testing":{"id":"service-installation/testing/load-testing","title":"Load testing","description":"There are several load testing tools available. The recommended tool is JMeter as the test plan can be deployed to Azure. The JMeter test plan is located in the loadtest folder. The test plan is configured to run 100 concurrent users, generating 4 requests per minute.","sidebar":"tutorialSidebar"},"service-installation/testing/testing":{"id":"service-installation/testing/testing","title":"Proxy service","description":"There are various options to test the endpoint. The simplest is to use Curl from either PowerShell or a Bash/zsh terminal. For example:","sidebar":"tutorialSidebar"}}}')}}]);